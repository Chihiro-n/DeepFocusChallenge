ゼロショットで画像のボケを推定するモデルの調査
背景と課題

画像の焦点ボケ（デフォーカスぼけ）を正確に推定することは難しい課題です。人間の熟練技術者であれば、明るさやコントラストが多少変わっても「ピントが合っているか/ぼけているか」を直感的に見抜けます。しかし機械学習モデルでは、トレーニング時と少し条件が変わっただけで予測が大きく崩れることがあります
arxiv.org
。特に既存のCNNベースモデル（例えばtimmライブラリの各種バックボーン）は画像中のテクスチャやコントラスト強度に過剰適応しがちで、日ごとの測定条件変動（ドメインシフト）に弱い可能性が指摘されています。このため、ある条件では高精度でも別条件では全く通用しないことが起こります。ゼロショットで画像のボケ量を推定できるモデルとは、追加の再学習なしに未知の画像ドメインでもボケを正しく評価できるモデルを指します。

本調査では、追加の教師データや再訓練を必要とせずに画像のぼけ具合を判定・定量化するアプローチをまとめます。具体的には、カメラや条件に依存しない汎用的な焦点ぼけ指標や、事前学習済みモデルを活用したゼロショット推定手法に注目します。

従来のノンラーニングによるボケ指標（ゼロショット手法）

追加学習を要さない伝統的手法として、画像のシャープネスやボケを測るノンリファレンス指標が古くから研究されています。例えば:

ラプラシアンの分散やTenengrad値などのエッジ勾配強度に基づく指標は、ピントが合っている画像ほど高周波成分（エッジ）が多いことを利用し、手軽にブレやボケ度合いを測定します。これらはオートフォーカスアルゴリズムにも使われますが、画像の明るさ・コントラスト変化に弱く、絶対的なボケ量推定には不向きです。

CPBD (Cumulative Probability of Blur Detection)
ivulab.asu.edu
は、確率的ぼけ検出モデルに基づくノンリファレンス画質指標です。エッジ上のぼけ具合が人間に「判別可能」になる確率を累積計算し、0～1のスコアでシャープネスを定量化します
ivulab.asu.edu
。Narvekarらの研究
ivulab.asu.edu
によれば、CPBDはガウスぼけやJPEG2000劣化に対して他の既存指標より良好な相関を示しています。**Just Noticeable Blur (JNB)**と呼ばれる人間の閾値モデルを取り入れているのが特徴です。

Shiら (CVPR 2015) のJNB検出とぼけ強度推定手法では、エッジパッチのスパース表現を解析し、パッチごとのぼけ量（ガウスぼけの標準偏差σ）を推定しています
openaccess.thecvf.com
openaccess.thecvf.com
。エッジのぼけにより辞書表現のスパース度合いが変化する現象を利用し、得られた特徴量とぼけ標準偏差σとの安定した関係をロジスティック関数でフィッティングすることで、微小なぼけでも定量評価可能としました
openaccess.thecvf.com
。この手法では画像内の空間的なぼけマップも生成できます。ただし、著者らも述べているように高頻度テクスチャ領域では精度が低下します
openaccess.thecvf.com
。追加の学習データなしに汎用的な性能を得るのは難しく、ノイズや被写体の模様によっては誤判定が生じる問題があります
openaccess.thecvf.com
openaccess.thecvf.com
。実際、エッジ上の局所的なぼけ推定結果を全体に補間する方式
openaccess.thecvf.com
や、勾配・周波数統計に基づく方式
openaccess.thecvf.com
は、小さなぼけやテクスチャのある領域での誤検出が報告されています。

以上のような従来型のぼけ評価アルゴリズムは、いずれも**学習不要（ゼロショットで適用可能）**ですが、画像条件が変わっても安定してぼけ量を評価できるとは限りません。特にSEM画像のようにコントラストが日によって大きく異なるケースでは、これらの単純指標だけで汎用的に対処するのは困難です。

深層学習を用いたゼロショットぼけ推定アプローチ

近年は深層学習を活用しつつ、追加の再学習なしでぼけを推定しようとする試みも現れています。ポイントは、大量の事前知識を持つモデルや物理モデルを利用して、新しい画像でも即座にぼけ量を評価できるようにすることです。

自己教師あり・単一画像ベースの手法:
Deep Image Prior (DIP)の考え方を応用し、1枚の入力画像からシャープな画像とぼけカーネルを同時に推定する手法があります。RenらのSelfDeblur
github.com
（2020年）では、乱数で初期化した2つのCNN（1つは潜在的なシャープ画像生成器、もう1つはぼけカーネル生成器）を用意し、入力のボケ画像に対してブラインド・デコンボリューションを行います
eee.hku.hk
。損失関数は再構成誤差（生成したシャープ画像 * 推定カーネルの畳み込み＝入力画像に一致）に加え、画像側にはTV正則化、カーネル側には回転対称性・滑らかさの事前拘束を課しています
eee.hku.hk
eee.hku.hk
。この方法では各入力画像ごとにネットワークをランダム初期化から学習するため計算コストは高いものの、外部のデータセットや事前学習なしでその画像固有のぼけを解析できます
eee.hku.hk
。実験では、顕微鏡で意図的にピントを外した画像に適用し、シャープな再構成像と物理的に意味のあるぼけカーネルの推定に成功しています
eee.hku.hk
。このような自己完結型モデルは極端なゼロショット推定と言え、どんなドメインの画像にも適用可能な柔軟性があります。ただし収束に時間がかかり、結果品質もネットワーク初期化やパラメータに依存するため、実用上は工夫が必要です。

事前学習済み大規模モデルの活用:
汎用的な視覚モデルや生成モデルに内包された知識を利用して、追加学習なしでぼけ評価に転用する研究もあります。例えばCLIPのような視覚と言語の巨大モデルは、「ぼけている写真」「鮮明な写真」といったテキストの概念を理解している可能性があります。実際、CLIP-IQA
openaccess.thecvf.com
arxiv.org
という手法ではCLIPをそのままノンリファレンス画質評価に応用し、テキストプロンプトで「画像の質」が高いか低いかを判定させています。CLIP-IQAの著者らは品質関連のテキストプロンプトを工夫することで、MOS（主観評価スコア）のゼロショット予測がある程度可能なことを示しました
arxiv.org
。しかしCLIP単体では学習データとのドメインギャップもあり、全評価指標で最先端には及ばないという報告もあります
openaccess.thecvf.com
。そこでKwonら（2024年）は、CLIPからぼけ・ノイズ・過剰露光など5つの品質属性に関する知識を抽出し、大規模未ラベル画像で生成した疑似ラベルでIQAモデルを事前学習するATTIQA手法を提案しています
arxiv.org
。彼らのフレームワークでは「Blurry image（ぼやけた画像）」 vs 「Distinct image（くっきりした画像）」等のテキストを用いてCLIPが画像のどの属性に該当するかスコアを出し、それを擬似教師としてモデルを学習させました
arxiv.org
。このように大規模事前モデルの言語知識を活用することで、限定的なデータでも高い一般化性能を発揮し、異なるデータセット間でも性能劣化が少ない最先端の結果を達成しています
arxiv.org
arxiv.org
。これはぼけ検出にも応用可能なアプローチで、実際「画像がどれだけぼやけているか」を言語で記述しスコア化することでゼロショット推定を行う研究とみなせます。

拡散モデル・生成モデルによるアプローチ:
近年注目の拡散モデルもゼロショットぼけ推定に寄与する可能性があります。例えばMarigoldと呼ばれる事前学習済み拡散モデルを使った研究では、本来は単一画像からスケール不変な深度推定を行う拡散モデル（Marigold）に対し、ピント差のある2枚の画像（小絞りと大絞り）を与えてデフォーカス量に関する手がかりを注入し、モデルの予測する相対深度に絶対スケールを復元することに成功しました
arxiv.org
。Talegaonkarら (2025年) のこの手法では追加の再学習なし（training-free）で、拡散モデルの生成する深度マップを調整し、ゼロショットでメートル単位の距離推定を可能にしています
arxiv.org
。ポイントは、光学的なデフォーカスの物理モデルを損失関数に組み込み、生成画像を微調整していることです
arxiv.org
。これと直接同じことはできなくても、例えば単一の拡散モデルに対して入力画像がぼけていれば「そのぼけ具合を再現するノイズ付加量」を推定する、といった応用も考えられます。実際、Scientific Reports (2025) の研究では、スコアベース拡散モデルによってペアデータなしでリアルな焦点ぼけの除去（デブラー）を行う手法が示されています
nature.com
nature.com
。この方法では、鮮明画像の分布を学習したスコアネットワークを用い、入力ぼけ画像を徐々に鮮明化する逆拡散過程を実現しました。拡散モデルの反復再構成により細部が徐々に改善し、生成像の分布が鋭敏な画像に近づいていくと報告されています
nature.com
。興味深いことに、このアプローチはオールインフォーカスとボケ画像のペアを用意せずに訓練でき、従来法より約13.4%のPSNR向上を達成しています
nature.com
。このような生成モデルの事前知識や物理的なレンズモデルを組み合わせた手法は、未知の画像でも物理的に一貫したぼけ評価ができる潜在力があります。例えば、近年の生成モデル研究では薄レンズモデルを拡散モデルに組み込み、任意の被写界深度効果を写実的に付与・制御することにも成功しています
arxiv.org
。同様に、逆問題としてレンズぼけの度合いを推定することも、十分な事前知識があれば可能と考えられます。

応用と展望

上述のように、「ゼロショット」で画像のぼけを推定するには、物理モデルに基づく不変量の活用と大規模事前モデルの知識がカギになります。具体的なアプローチとしては:

深度情報の活用: ぼけは基本的にZ軸方向（被写体深度）のズレに起因します。そこで単一画像からの深度推定モデルを活用し、そこからピント面からの距離を推定してぼけ量に結びつける研究もあります
arxiv.org
arxiv.org
。例えばNazirらの手法では、デフォーカス画像から同時に深度マップと鮮明画像を推定し、深度精度とデブラー精度の両方を高めています
nature.com
。カメラごとのパラメータに依存せず深度とぼけの関係を扱う試みもあり、Wigaisinhaら (2024年) は光学方程式に基づく補正でカメラ非依存の深度-from-defocusを実現しています
arxiv.org
arxiv.org
。深度推定そのものはゼロショットではありませんが、一度学習すれば未知画像にも適用でき、物理的に解釈しやすい特徴（距離）に変換できる点で有用です。

リファレンス画像によるキャリブレーション: ドメインシフトに対しては、各ドメインごとの基準となるピント合致画像を与え、モデルの出力を補正する戦略も考えられます。例えば提供された参照用フォーカス画像と比較してエッジのコントラスト低下率を測定し、それをぼけ量指標にする方法です。これは古典的なMTF（Modulation Transfer Function）の発想に近く、各条件でシャープな画像がわかっていれば未知画像の鮮鋭度低下を定量化できます。ただし参照画像取得が必要になるため、本質的なゼロショットとは少し異なります。

エッジプロファイルの解析: 画像中の特徴エッジを検出し、そのエッジの広がり具合（エッジ勾配の緩慢さ）を測定する手法もロバストなぼけ推定に有用です。エッジ勾配をロバストに評価するには、コントラスト正規化やノイズ除去を組み合わせる必要があります。例えばLoGフィルタでマルチスケールにエッジ応答を見てピーク幅を測る、といったアルゴリズムが考えられます。これらはシンプルですが、画像ごとに適応的にエッジとノイズを区別できれば、学習なしでもある程度一般化可能です。

まとめると、ゼロショットでの画像ぼけ推定には**「物理法則に裏打ちされた特徴」と「大規模データから学習された知見」の両輪が重要です。前者は深度やPSFといった不変量を提供し、後者は新奇な入力にも対応できる一般知識を提供します。現在の研究最前線では、拡散モデルや視覚言語モデルといった汎用AIモデルを上手く活用しつつ、光学的整合性を担保する工夫が見られます
arxiv.org
nature.com
。真に実用的なフォーカス判定モデルを得るには、これらのアプローチを組み合わせ、人間の視覚に迫るロバストさで純粋な光学的ボケ**を見抜くことが求められています。

参考文献: 脚注に示した通り【1†】【4†】【9†】【13†】【17†】【18†】【21†】など、ゼロショットでのぼけ推定や関連分野の最新研究動向を参照してください。それらは本回答の調査に使用した情報源であり、さらなる詳細が記載されています。